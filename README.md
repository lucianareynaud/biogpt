# ğŸ§¬ Genomic-LLM: AI-Powered Genomic Analysis Platform

A comprehensive SaaS platform for analyzing 23andMe genomic data using ACMG classification guidelines and AI-powered interpretations with PubMedBERT.

## âœ¨ Features

- **ğŸ”¬ ACMG-2015 Classification**: Automated variant classification following ACMG-AMP guidelines
- **ğŸ¤– AI-Powered Interpretations**: PubMedBERT-based clinical interpretations
- **ğŸ“Š Population Data Integration**: ClinVar and gnomAD database integration
- **ğŸ“„ Professional Reports**: PDF reports in Portuguese (PT-BR) and English
- **ğŸ’¬ Intelligent Chat**: RAG-powered conversations about genomic results
- **ğŸ”’ Privacy-First**: Local processing, educational use only
- **ğŸŒ Modern UI**: Beautiful Next.js 15 interface with Tailwind CSS

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   LLM Service   â”‚
â”‚   Next.js 15    â”‚â—„â”€â”€â–ºâ”‚   FastAPI       â”‚â—„â”€â”€â–ºâ”‚   PubMedBERT    â”‚
â”‚   Tailwind CSS  â”‚    â”‚   Python 3.11   â”‚    â”‚   Transformers  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Vector DB     â”‚    â”‚   Database      â”‚    â”‚   File Storage  â”‚
        â”‚   ChromaDB      â”‚    â”‚   DuckDB        â”‚    â”‚   Local FS      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Colima** (lightweight Docker runtime for macOS/Linux) or Docker Desktop
- Docker Compose
- ~5GB free disk space
- At least 8GB RAM (recommended 16GB)

### Colima Installation (Recommended for macOS)

If you don't have Colima installed:

```bash
# Install via Homebrew (macOS)
brew install colima

# Install via package manager (Linux)
# See https://github.com/abiosoft/colima for Linux installation

# Start Colima with sufficient resources
colima start --cpu 4 --memory 8 --disk 20
```

For other operating systems or Docker Desktop users, ensure Docker is running before proceeding.

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-org/genomic-llm.git
   cd genomic-llm
   ```

2. **Start the platform**
   ```bash
   chmod +x start.sh
   ./start.sh
   ```
   
   The startup script will automatically:
   - Detect and start Colima if available (or use Docker Desktop)
   - Create environment configuration
   - Build and start all services
   - Initialize databases with ClinVar and gnomAD data
   - Set up AI embeddings for chat functionality

3. **Access the platform**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs
   - ChromaDB: http://localhost:8002

### First Analysis

1. Open http://localhost:3000
2. Upload your 23andMe .txt file
3. Wait for processing (5-15 minutes)
4. View results, download reports, and chat with AI

### Troubleshooting

#### Colima Issues

If you encounter Docker-related errors:

```bash
# Check Colima status
colima status

# Restart Colima if needed
colima restart

# Stop and start with specific resources
colima stop
colima start --cpu 4 --memory 8 --disk 20

# Check Docker is working
docker --version
docker info
```

#### Port Conflicts

If ports are already in use, you can modify the docker-compose.yml file or stop conflicting services:

```bash
# Check what's using the ports
lsof -i :3000  # Frontend
lsof -i :8000  # Backend API
lsof -i :8001  # LLM Service
lsof -i :8002  # ChromaDB
```

#### Memory Issues

If containers are crashing due to memory:

```bash
# Increase Colima memory allocation
colima stop
colima start --cpu 4 --memory 12 --disk 20
```

#### Stopping the Platform

To cleanly stop all services:

```bash
# Stop all containers
docker compose down

# Optional: Stop Colima to free up system resources
colima stop
```

## ğŸ“ Project Structure

```
genomic-llm/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI application
â”‚   â”‚   â”œâ”€â”€ dependencies.py    # Database connections
â”‚   â”‚   â”œâ”€â”€ models/            # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ routers/           # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â””â”€â”€ templates/         # Jinja2 templates
â”‚   â”œâ”€â”€ scripts/               # Data ingestion scripts
â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ frontend/                  # Next.js frontend
â”‚   â”œâ”€â”€ app/                   # App router
â”‚   â”œâ”€â”€ components/            # React components
â”‚   â””â”€â”€ package.json           # Node dependencies
â”œâ”€â”€ llm_service.py             # Standalone LLM service
â”œâ”€â”€ docker-compose.yml         # Orchestration
â”œâ”€â”€ start.sh                   # Startup script
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Configuration

### Environment Variables

Create `.env` files in the root directory:

```bash
# Database Configuration
DUCKDB_PATH=/app/data/genomic.duckdb
CHROMA_PERSIST_DIRECTORY=/app/data/chroma

# LLM Configuration
LLM_SERVICE_URL=http://llm:8001
HUGGINGFACE_HUB_CACHE=/app/models

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Frontend Configuration
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### Data Sources

During system initialization, the platform automatically downloads and caches reference data:
- **ClinVar**: Variant clinical significance database (~2GB) - Downloaded once during setup from NCBI FTP
- **gnomAD**: Population frequency data (variable size) - Downloaded once during setup from Broad Institute
- **PubMedBERT**: Pre-trained biomedical language models (~500MB) - Downloaded during LLM service startup from HuggingFace Hub

**Important**: These are public reference databases downloaded once during setup and cached locally. Your personal genomic data is never uploaded to external services.

## ğŸ“Š Data Processing Pipeline

1. **File Upload**: 23andMe .txt file validation and storage
2. **Variant Parsing**: Extract rsIDs, positions, and genotypes
3. **Database Lookup**: Cross-reference with ClinVar and gnomAD
4. **ACMG Classification**: Apply simplified ACMG-2015 criteria
5. **AI Interpretation**: Generate clinical interpretations with PubMedBERT
6. **Report Generation**: Create professional PDF reports
7. **Vector Indexing**: Build embeddings for RAG chat functionality

## ğŸ¤– AI Components

### PubMedBERT Integration
- **Model**: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext
- **Embeddings**: intfloat/e5-small-v2
- **Tasks**: Text generation, embeddings, variant interpretation

### RAG (Retrieval-Augmented Generation)
- **Vector Database**: ChromaDB for semantic search
- **Knowledge Base**: ClinVar annotations + ACMG guidelines
- **Context**: Analysis-specific variant data

## ğŸ“„ Report Generation

### Supported Languages
- **Portuguese (PT-BR)**: Default language with medical terminology
- **English (EN)**: International standard version

### Report Sections
- Executive Summary with key findings
- ACMG Classification distribution
- Clinically significant variants
- Gene summaries and interpretations
- Methodology and limitations
- Professional disclaimers

## ğŸ”’ Privacy & Security

### Data Protection
- **Local Processing**: All data processed locally, never shared
- **Temporary Storage**: Files deleted after analysis
- **No Cloud Upload**: Complete air-gapped operation
- **Educational Use**: Not for medical diagnosis

### Compliance
- ACMG-AMP 2015 guidelines implementation
- Medical disclaimers and limitations
- Educational use notifications

## ğŸ§ª Testing

### Sample Data
Test the platform with the provided sample file:
```bash
# Use the sample 23andMe file
cp test_data/sample_23andme.txt /path/to/upload/
```

### API Testing
```bash
# Test backend health
curl http://localhost:8000/health

# Test LLM service
curl http://localhost:8001/health

# Upload test file
curl -X POST "http://localhost:8000/api/v1/genome-upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@test_data/sample_23andme.txt"
```

## ğŸ› ï¸ Development

### Backend Development
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Development
```bash
cd frontend
npm install
npm run dev
```

### LLM Service Development
```bash
python llm_service.py
```

## ğŸ“š API Documentation

### Key Endpoints

#### Genome Upload
```bash
POST /api/v1/genome-upload          # Upload 23andMe file
POST /api/v1/genome-upload/{id}/process  # Start analysis
GET  /api/v1/genome-upload/{id}/status   # Check progress
GET  /api/v1/genome-upload/{id}          # Get results
```

#### Reports
```bash
POST /api/v1/reports/generate       # Generate PDF report
GET  /api/v1/reports/{id}/download  # Download report
```

#### Chat
```bash
POST /api/v1/chat/session          # Create chat session
POST /api/v1/chat/message          # Send message
```

Full API documentation available at: http://localhost:8000/docs

## ğŸš¨ Important Disclaimers

âš ï¸ **This system is for educational and research purposes only**

- **Not for medical diagnosis**: Results should not be used for medical decisions
- **Consult professionals**: Always consult healthcare providers for genetic counseling
- **Limited scope**: Only analyzes variants present in 23andMe data
- **Evolving science**: Genetic interpretation guidelines change over time
- **No warranty**: Software provided as-is without medical guarantees

## ğŸ”§ System Requirements

### Minimum Requirements
- **CPU**: 4 cores, 2.0 GHz
- **RAM**: 8GB (16GB recommended)
- **Storage**: 10GB free space
- **Network**: Internet for initial data download

### Recommended Setup
- **CPU**: 8+ cores, 3.0+ GHz
- **RAM**: 16-32GB for faster processing
- **Storage**: SSD with 20GB+ free space
- **GPU**: Optional, for faster AI inference

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt
npm install --dev

# Run tests
pytest backend/tests/
npm test


# Format code
black backend/
prettier --write frontend/
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **ACMG-AMP**: For variant classification guidelines
- **ClinVar**: NIH genetic variant database
- **gnomAD**: Genome Aggregation Database
- **Microsoft**: PubMedBERT model
- **23andMe**: Direct-to-consumer genetic testing
- **Open Source Community**: For the amazing tools and libraries

## ğŸ“ Support

- **Documentation**: [Wiki](https://github.com/your-org/genomic-llm/wiki)
- **Issues**: [GitHub Issues](https://github.com/your-org/genomic-llm/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/genomic-llm/discussions)

---

**Made with â¤ï¸ for the genomics community**

*Remember: This tool is for educational purposes. Always consult qualified healthcare providers for medical advice.* 